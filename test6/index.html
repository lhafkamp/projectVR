<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>VR</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <script src="https://aframe.io/releases/0.2.0/aframe.min.js"></script>
  <script src="../assets/js/aframe-lazyload.js"></script>

  <style type="text/css">
    canvas { transition: opacity .2s; background: #000; }
  </style>
</head>

<body>
  <a-scene data-scene="binnen">
    <a-assets>
      <video id="video1" src="../assets/video/school.mp4"  lazy-load="chunk: 0; src:../assets/video/school.mp4; id: video1" autoplay muted loop crossorigin></video>
      <video id="video2" src="../assets/video/metro.mp4"   lazy-load="chunk: 1; src:../assets/video/school.mp4; id: video2" autoplay muted loop crossorigin></video>
      <video id="video3" src="../assets/video/cs.mp4"      lazy-load="chunk: 1; src:../assets/video/school.mp4; id: video3" autoplay muted loop crossorigin></video>
      <video id="video4" src="../assets/video/csplein.mp4" lazy-load="chunk: 2; src:../assets/video/school.mp4; id: video4" autoplay muted loop crossorigin></video>
      <video id="video5" src="../assets/video/duif.mp4"    lazy-load="chunk: 2; src:../assets/video/school.mp4; id: video5" autoplay muted loop crossorigin></video>

      <audio id="voiceOverIntro" src="../assets/sound/vrvoice.mp3"
              autoplay crossorigin preload="auto"></audio>
    </a-assets>

    <a-curvedimage data-ui="curvedimage" src="../assets/img/besteuip2.png" rotation="0 130 0" radius="4" theta-length="100" height="3" scale=".5 .5 .5"></a-curvedimage>

    <a-videosphere data-element="videosphere" src="../assets/img/roomp2.png">
      <a-root>
        <a-entity geometry="primitive: sphere" material="shader: flat; src: url(../assets/img/roomp2.png);" scale="1 1 1"></a-entity>
      </a-root>
    </a-videosphere>

    <a-entity camera look-controls>
      <a-cursor id="cursor"
        animation__click="property: scale; startEvents: click; from: 0.1 0.1 0.1; to: 1 1 1; dur: 150"
        animation__fusing="property: fusing; startEvents: fusing; from: 1 1 1; to: 0.1 0.1 0.1; dur: 1500"
        event-set__1="_event: mouseenter; color: springgreen"
        event-set__2="_event: mouseleave; color: white"
        raycaster="objects: .link"></a-cursor>
    </a-entity>
  </a-scene>

  <script type="text/javascript">
    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    const skyElem = document.querySelector('[data-element="videosphere"]');
    const UIElem = document.querySelector('[data-ui="curvedimage"]');
    const voiceOverIntro = document.querySelector('#voiceOverIntro');

    let currentLevel = 0;

    const recognition = new SpeechRecognition();
    recognition.interimResults = true;

    function goToLevel(level) {
      const canvasElem = document.querySelector('canvas');

      console.log('current level:', currentLevel);
      console.log('target level:', level);

      if (voiceOverIntro.paused && (currentLevel != level)) {
        canvasElem.style.opacity = 0;
        UIElem.setAttribute('opacity', '0');

        currentLevel = level;

        setTimeout(() => {
          canvasElem.style.opacity = 1;
        }, 2000);

        setTimeout(() => {
          if(level === 0) {
            skyElem.setAttribute('src', '../assets/img/roomp2.png');
            UIElem.setAttribute('opacity', '1');
          } else {
            skyElem.setAttribute('src', `#video${level}`);

            const currentVideo = document.querySelector(`#video${level}`);
            currentVideo.play();
            currentVideo.removeAttribute('muted');

            currentVideo.currentTime = 0;
          }
        }, 1000);
      }
    }

    recognition.addEventListener('result', e => {
      const transcript = Array.from(e.results)
        .map(result => result[0])
        .map(result => result.transcript)
        .join('');

        if(transcript.includes('level 1')) {
          goToLevel(1);
        }
        else if(transcript.includes('level 2')) {
          goToLevel(2);
        }
        else if(transcript.includes('level 3')) {
          goToLevel(3);
        }
        else if(transcript.includes('level 4')) {
          goToLevel(4);
        }
        else if(transcript.includes('level 5')) {
          goToLevel(5);
        }
        else if(transcript.includes('stop') || transcript.includes('star') || transcript.includes('help') || transcript.includes('quit')) {
          goToLevel(0);
        }

        console.log(transcript);
    });

    recognition.addEventListener('end', recognition.start);
    recognition.start();
  </script>
</body>
</html>
